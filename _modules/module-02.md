---
title: Representation learning 
---

Oct 11
: [Pretraining and finetuning (basics)](https://nyu-cs2590.github.io/course-material/fall2023/lecture/lec06/main.pdf) [[recording]()]
  : **HW 2 due**{: .label .label-red }
  : **HW 3 out**{: .label .label-green }
: 1. Data
  2. Self-supervised learning
  3. Adaptation / finetuning 

Oct 16           
: **Section**{: .label .label-purple } Transformer 
  [[slides](https://nyu-cs2590.github.io/course-material/fall2023/section/sec06/sec06.pdf)]
  [[notebook](https://nyu-cs2590.github.io/course-material/fall2023/section/sec06/sec06.ipynb)]
  <!-- [[recording](https://nyu.zoom.us/rec/play/Qq7iMc11LcKU26l2ADI8eWjnX6cK7r6Tm9uEj5Lyl9qIfUuL1fiIQnQJ2oWo0VKJpZtyn56u_Eqjm4J7.hQdGPIdfEPM6gS8x)] -->

Oct 18 
: [Pretraining and finetuning (advanced)]() [[recording]()]
  : 
: 1. Efficient pretraining 
  2. Efficient finetuning 
  3. Additional reading: [Efficient transformers: a survey](https://arxiv.org/abs/2009.06732)

Oct 23           
: **Section**{: .label .label-purple } Hugginface tutorial

Oct 25
: [Holistic evaluation]() 
  : **Proposal due**{: .label .label-red }
: 1. Behavioral tests 
  2. Fairness, robustness, privacy
  3. Additional reading: [Holistic evaluation of language models](https://arxiv.org/abs/2211.09110)

Oct 30           
: **Section**{: .label .label-purple } NLP benchmarks 

